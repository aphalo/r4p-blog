{
  "hash": "818449f0b727515d4a9a3ae9aaba7f5a",
  "result": {
    "markdown": "---\ntitle: \"Model fitting in R\"\nsubtitle: \"An introduction\"\nauthor: \"Pedro J. Aphalo\"\ndate: 2023-05-30\ndate-modified: 2023-06-29\ncategories: [R, model fitting]\nkeywords: [predicted values, residual values, parameter estimates, model formulas]\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n---\n\n\n## Introduction\n\nFitting a model to data consists in finding the parameter values that best\nexplain the data or observations. These parameter values are estimates of\nthose in a larger population of possible observations from which we have\ndrawn a sample or subset.\n\n::: callout-tip\nYou may want to play with the my \n[linear regression Shiny App](https://aphalo.shinyapps.io/class01-practical/#21) \nto get a better sense of how the size of the response and error variation \naffect the linear model fit to succesive sample draws from a normally\ndistributed population of artificial observations.\n:::\n\nModel selection involves comparing models that differ in their structure, i.e., \nin the formula that relates parameters and data.\n\nIn general, there are many different aspects of a model fit that we may be\ninterested in. The most computationally intensive step is the fitting itself.\nThus R's approach is to save the results from fitting, or _fitted model_, and\nseparately query it for different derived numerical and graphical output as \nneeded.\n\n## Fitting a model\n\n::: callout-tip\nIn this page code chunks are \"folded\" so as to decrease the clutter. Above the R\noutput, text or plots, you will find a small triangle followed by \"Code\".\nClicking on the triangle \"unfolds\" the code chunk making visible the R code used\nto produce the output shown.\nThe code in the chunks can be copied by clicking on the top right corner, where\nan icon appears when the mouse cursor hovers over the code listing.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggpmisc)\nlibrary(broom)\ntheme_set(theme_bw(16))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19065)\n# set.seed(4321) # change or comment out to get different psedorandom values\n# generate artificial data\nx <- 1:24\ny <- (x + x^2 + x^3) + rnorm(length(x), mean = 0, sd = mean(x^3) / 2)\ny <- y / max(y)\nmy.data <- data.frame(x, \n                      y, \n                      group = c(\"A\", \"B\"), \n                      y2 = y * c(1, 2) + c(0, 0.2),\n                      block = c(\"a\", \"a\", \"b\", \"b\"),\n                      wt = sqrt(x))\n```\n:::\n\n\nIn R we usually save the fitted model object into a variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfm1 <- lm(formula = y ~ poly(x, 3), data = my.data)\n```\n:::\n\n\nThen we query this object saved in the variable, here `fm1`, with different methods, \nfor example `summary()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = y ~ poly(x, 3), data = my.data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.24817 -0.07635  0.01945  0.08890  0.18264 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.25644    0.02525  10.154 2.44e-09 ***\npoly(x, 3)1  1.49842    0.12372  12.111 1.15e-10 ***\npoly(x, 3)2  0.55768    0.12372   4.508 0.000215 ***\npoly(x, 3)3 -0.06142    0.12372  -0.496 0.625015    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1237 on 20 degrees of freedom\nMultiple R-squared:  0.8932,\tAdjusted R-squared:  0.8772 \nF-statistic: 55.75 on 3 and 20 DF,  p-value: 6.793e-10\n```\n:::\n:::\n\n\n## Model fitting flowcharts\n\n\n```{mermaid}\n%%| label: fig-barebones\n%%| fig-cap: A minimalist diagram of model fitting in R.\n%%{init: {\"htmlLabels\": true} }%%\n\nflowchart LR\n  A(<i>model formula</i>) --> B[model fit\\nfunction] --> C(model fit\\nobject) --> D1['diagnostics' plots]\n  AA(<i>observations</i>) --> B\n  C --> D2[query methods]\n```\n\n```{mermaid}\n%%| label: fig-lm\n%%| fig-cap: A diagram of linear-model (LM) fitting in R.\n%%{init: {\"htmlLabels\": true} }%%\n\nflowchart LR\n  A1(<i>model formula</i>) --> B[\"<code>lm()</code>\"] --> C(<code>lm</code> object) --> C1[\"<code>plot()</code>\"]\n  A2(<i>observations</i>) --> B\n  A3(<i>weights</i>) -.-> B\n  C --> C2[\"<code>summary()</code>\"]\nC --> C3[\"<code>anova()</code>\"]\nC --> C4[\"<code>residuals()</code>\"]\nC --> C5[\"<code>fitted()</code>\"]\nC --> C6[\"<code>AIC()</code>\"]\nC --> C7[\"<code>BIC()</code>\"]\nC --> C8[\"<code>coefficients()</code>\"]\nC --> C11[\"<code>formula()</code>\"]\nC --> C12[\"<code>weights()</code>\"]\nC --> C9[\"<code>confint()</code>\"]\nC --> C10[\"<code>predict()</code>\"]\nBB(\"<i>new data</i>\") --> C10\n```\n\n```{mermaid}\n%%| label: fig-glm\n%%| fig-cap: A diagram of generalized-linear-model (GLM) fitting in R. Query methods as in @fig-lm.\n%%{init: {\"htmlLabels\": true} }%%\n\nflowchart LR\n  A1(<i>model formula</i>) --> B[\"<code>glm()</code>\"] --> C(<code>glm</code> object) --> C1[query methods]\n  A2(<i>observations</i>) --> B\n  A3(<i>weights</i>) -.-> B\n  A4(<i>family</i> and <i>link</i>) --> B\n```\n\n```{mermaid}\n%%| label: fig-nls\n%%| fig-cap: A diagram of nonlinear least squares (NLS) model fitting by numerical approximation in R. Query methods similar to those in @fig-lm.\n%%{init: {\"htmlLabels\": true} }%%\n\nflowchart LR\n  A1(<i>model formula</i>) --> B[\"<code>gls()</code>\"] --> C(<code>nls</code> object) --> C1[query methods]\n  A2(<i>observations</i>) --> B\n  A3(<i>weights</i>) -.-> B\n  A5(<i>starting values</i>) --> B\n```\n\n\n## Model selection flowchart\n\nModel selection can be done manually by comparing models fitted individually or automatically using a stepwise approach.\n\n\n```{mermaid}\n%%| label: fig-lm-step\n%%| fig-cap: A diagram of linear-model (LM) fitting with stepwise model selection in R.\n%%{init: {\"htmlLabels\": true} }%%\n\nflowchart TB\n  A1(<i>model formula</i>) --> B[\"<code>lm()</code>\"] --> C(<code>lm</code> object)\n  A2(<i>observations</i>) --> B\n  A3(<i>weights</i>) -.-> B\n  C --> CI[query methods]\n  C --> C1[\"<code>step()</code>\"]\n  subgraph Z [\"<strong>Model selection</strong>\"]\n  C1 --> C3(<code>lm</code>  object)\n  z1(most complex\\n<i>model formula</i>) -.-> C1\n  z2(simplest nested\\n<i>model formula</i>) -.-> C1\n  C3 --> CF[query methods]\n  end\n  style Z fill:#fff\n```\n\n\n## What do the query methods return?\n\nI expect you to be already familiar with the ANOVA table, coefficient estimates and plots of residuals. But how does all this fit together? I will use plots to explain this.\n\nThe observations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point()\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-10-1.svg)\n:::\n:::\n\n\nThe fitted values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  stat_fit_fitted(formula = y ~ poly(x, 3), colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-11-1.svg)\n:::\n:::\n\n\nThe prediction line and its equation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  stat_poly_line(formula = y ~ poly(x, 3), se = FALSE) +\n  stat_poly_eq(formula = y ~ poly(x, 3),\n               mapping = use_label(\"eq\"))\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-12-1.svg)\n:::\n:::\n\n\nThe prediction line and $R^2$, $n$, $F\\textrm{-value}$ and $P\\textrm{-value}$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  stat_poly_line(formula = y ~ poly(x, 3), se = FALSE) +\n  stat_poly_eq(formula = y ~ poly(x, 3),\n               mapping = use_label(c(\"R2\", \"n\", \"F\", \"P\")))\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-13-1.svg)\n:::\n:::\n\n\n\nThe prediction line plus its 95% confidence band.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  stat_poly_line(formula = y ~ poly(x, 3), se = TRUE)\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-14-1.svg)\n:::\n:::\n\n\nThe prediction line plus its 95% confidence band with extrapolation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  geom_vline(xintercept = range(my.data$x), size = 0.33) +\n  stat_poly_line(formula = y ~ poly(x, 3), se = TRUE, fullrange = TRUE) +\n  expand_limits(x = c(-10, 40)) # an arbitrary range\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nâ„¹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-15-1.svg)\n:::\n:::\n\n\nThe residuals plotted as deviations from the prediction line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  stat_poly_line(formula = y ~ poly(x, 3), se = FALSE) +\n  stat_fit_deviations(formula = y ~ poly(x, 3), colour = \"red\", \n                      arrow = arrow(length = unit(0.33, \"lines\"), ends = \"both\"))\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-16-1.svg)\n:::\n:::\n\n\n\nThe residuals plotted as deviations from the fitted values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n         geom_point() +\n  stat_fit_deviations(formula = y ~ poly(x, 3), \n                      colour = \"red\", \n                      arrow = arrow(length = unit(0.33, \"lines\"), ends = \"both\")) +\n  stat_fit_fitted(formula = y ~ poly(x, 3), colour = \"blue\")\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-17-1.svg)\n:::\n:::\n\n\nThe residuals plotted on their own.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(my.data, aes(x = x, y = y)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  stat_fit_residuals(formula = y ~ poly(x, 3),\n                     colour = \"red\")\n```\n\n::: {.cell-output-display}\n![](R-model-fitting-intro_files/figure-html/unnamed-chunk-18-1.svg)\n:::\n:::\n\n\n\n::: callout-warning\nThe assumption of most usual model fitting procedures is that residuals are normally distributed and independent of the magnitude of the response variable, not that the observations themselves are normally distributed. Only in the simplest cases, such as comparing a mean against a constant, the residuals have the same distribution as the data but centred on zero instead of on the mean. In most other cases, this is not the case, as part of the variation among individual observations is accounted by terms in the fitted model, such as random effects, correlations or even variance covariates. The justification is that we use the residuals to estimate the _error_ variation and the tests of significance are based on this error variance estimate.\n\nIt is also of little use to test for the statistical significance of the deviations from these assumptions, as we should not expect in the real world for the assumptions to be ever exactly fulfilled. The power of tests increases with replication, but the bias introduced into estimates does not depend on significance, but on the magnitude of the deviations. Furthermore, the higher the replication, the less the bias introduced in the estimates by deviations from the assumptions. In other words, the more replicates we have smaller deviations from assumptions become detectable as significant, while the importance of deviations decreases.\n\nWhen there are very few replicates available, it is imposible to assess directly if observations come from a normally distributed population or not. In such cases, it can be wise to rely on previous information about the sampled population and sampling method used instead of on the current observations.\n:::\n\n::: callout-tip\nTo create the plots above I used packages 'ggplot2' and 'ggpmisc'. [Galleries\nof plot examples using 'ggpmisc' and some other\npackages](https://www.r4photobiology.info/galleries.html) are available at the\n[R for Photobiology web site](https://www.r4photobiology.info). They contain R\ncode folded in the same way as in this page.\n:::\n",
    "supporting": [
      "R-model-fitting-intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}